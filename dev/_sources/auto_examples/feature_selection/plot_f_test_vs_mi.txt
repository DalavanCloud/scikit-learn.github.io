

.. _example_feature_selection_plot_f_test_vs_mi.py:


===========================================
Comparison of F-test and mutual information
===========================================

This example illustrates the differences between univariate F-test statistics
and mutual information.

We consider 3 features x_1, x_2, x_3 distributed uniformly over [0, 1], the
target depends on them as follows:

y = x_1 + sin(6 * pi * x_2) + 0.1 * N(0, 1), that is the third features is completely irrelevant.

The code below plots the dependency of y against individual x_i and normalized
values of univariate F-tests statistics and mutual information.

As F-test captures only linear dependency, it rates x_1 as the most
discriminative feature. On the other hand, mutual information can capture any
kind of dependency between variables and it rates x_2 as the most
discriminative feature, which probably agrees better with our intuitive
perception for this example. Both methods correctly marks x_3 as irrelevant.



.. image:: images/plot_f_test_vs_mi_001.png
    :align: center




**Python source code:** :download:`plot_f_test_vs_mi.py <plot_f_test_vs_mi.py>`

.. literalinclude:: plot_f_test_vs_mi.py
    :lines: 23-

**Total running time of the example:**  0.26 seconds
( 0 minutes  0.26 seconds)
    